   ASCII它是由美国人发明的，符合他们的使用习惯，由一个字节（8个比特）组成最多可表示255，但是其他国家不能用啊，于是自己就搞了GBK（中国），Shift_JIS（日本）
Euc-kr（韩国），这样就太乱了，大家一起商量就搞了个Unicode，用两个字节表示一个字，但是美国人不同意了，为什么我们本来只需要一个字节就可以表示一个字，现在非
得用两个，增加了一倍的内存，所以又搞出了UTF8，UTF8里包含的ASCII码是用一个字节表示，其他的一般用两个字节表示。所以如果文件里面ASCII较多的话用utf8比Unicode节省内存。
python2.X里：
	Unicode.encode('utf8')#将Unicode变为utf8
	utf8.decode('utf8')#将utf8变为unicode
GBK也一样
######################################################################
#encoding:utf8

1,
	ascii码由美国人发明，长度为一个字节，8个二进制，最长表示256个字符，
标准的ascii为128个，前面一个bit为0，用后面7位表示128个ascii码。
2,
	为了兼容世界所有字符，重新编了一套Unicode，每个符号给予独一无二的编码，
现在可容纳100多万字符，这就意味着Unicode的编码变得特别多，也就不可能用1个
字节表示ASCII吗，因为解码的时候所有比特连在一起，会将你本来用来表示ascii码的
一个字节混淆（因为unicode编码太多，此ascii的编码可能与Unicode某个编码中的某
一段重复）;所以必须加长用来表示ascii的编码，以进行区别，但这就带来一个浪费内
存的问题。
3,
	所以出现了utf8,它用前N+1个比特表示它的长度N（除了单字节是用一个0比特表示,这时
的utf8编码与ascii编码一致，都是一个字节）,后面的编码直接从Unicode编码里面拿。所以它
不是全新的编码，是Unicode的一种实现方式，相比而言节省了内存（尤其是在以英文居多的时候）。
